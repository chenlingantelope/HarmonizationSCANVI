{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/data/yosef2/users/chenling/HarmonizationSCANVI\")\n",
    "import sys\n",
    "sys.path.append(\"/data/yosef2/users/chenling/HarmonizationSCANVI\")\n",
    "save_path = '../MarrowTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.models.vae import VAE\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "from scvi.dataset.dataset import GeneExpressionDataset\n",
    "from scvi.harmonization.utils_chenling import run_model\n",
    "from scvi.harmonization.utils_chenling import entropy_batch_mixing\n",
    "from scvi.metrics.clustering import select_indices_evenly\n",
    "from scvi.dataset.dataset import SubsetGenes\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from umap import UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotname='MarrowTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_droplet_metadata.csv already downloaded\n",
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_facs_metadata.csv already downloaded\n",
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_droplet_mat.h5ad already downloaded\n",
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_facs_mat.h5ad already downloaded\n",
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_droplet_metadata.csv already downloaded\n",
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_facs_metadata.csv already downloaded\n",
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_droplet_mat.h5ad already downloaded\n",
      "File /data/yosef2/scratch/chenling/scanvi_data/TM_facs_mat.h5ad already downloaded\n",
      "True\n",
      "Downsampling from 20508 to 17802 genes\n",
      "Downsampling from 5351 to 5351 cells\n",
      "Downsampling from 20508 to 14687 genes\n",
      "Downsampling from 4112 to 4112 cells\n",
      "Keeping 14590 genes\n",
      "Downsampling from 17802 to 1804 genes\n",
      "Downsampling from 5351 to 5351 cells\n",
      "Downsampling from 14687 to 1804 genes\n",
      "Downsampling from 4112 to 4112 cells\n",
      "Downsampling from 14590 to 1804 genes\n",
      "Downsampling from 9463 to 9463 cells\n"
     ]
    }
   ],
   "source": [
    "from scvi.dataset.muris_tabula import TabulaMuris\n",
    "dataset2 = TabulaMuris('droplet', save_path='/data/yosef2/scratch/chenling/scanvi_data/')\n",
    "dataset1 = TabulaMuris('facs', save_path='/data/yosef2/scratch/chenling/scanvi_data/')\n",
    "dataset1.subsample_genes(dataset1.nb_genes)\n",
    "dataset2.subsample_genes(dataset2.nb_genes)\n",
    "\n",
    "gene_dataset = GeneExpressionDataset.concat_datasets(dataset1, dataset2)\n",
    "seurat_latent, batch_indices, labels, keys, stats = run_model('readSeurat', gene_dataset, dataset1, dataset2,\n",
    "                                                       filename=plotname)\n",
    "dataset1, dataset2, gene_dataset = SubsetGenes(dataset1, dataset2, gene_dataset, plotname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seurat_latent, batch_indices, labels, keys, stats = run_model('readSeurat', gene_dataset, dataset1, dataset2,\n",
    "                                                       filename=plotname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def transfer_nn_labels(latent_array, labels_array, batch_indices_array):\n",
    "    # Transfer labels from batch 0 to batch 1 using scVI\n",
    "    latent_labelled = latent_array[batch_indices_array.ravel() == 0, :]\n",
    "    labels_labelled = labels_array[batch_indices_array.ravel() == 0]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "    neigh = neigh.fit(latent_labelled, labels_labelled)\n",
    "    return neigh.predict(latent_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5551154613494873\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "transfer_nn_labels(seurat_latent, labels, batch_indices)\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9463, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seurat_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.dataset import GeneExpressionDataset\n",
    "from scvi.models import VAE\n",
    "from scvi.inference import UnsupervisedTrainer, AlternateSemiSupervisedTrainer\n",
    "from scvi.inference.posterior import get_IS_bayes_factors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scvi.models.scanvi import SCANVI\n",
    "\n",
    "def transfer_nn_labels(latent_array, labels_array, batch_indices_array):\n",
    "    # Transfer labels from batch 0 to batch 1 using scVI\n",
    "    latent_labelled = latent_array[batch_indices_array.ravel() == 0, :]\n",
    "    labels_labelled = labels_array[batch_indices_array.ravel() == 0]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "    neigh = neigh.fit(latent_labelled, labels_labelled)\n",
    "    return neigh.predict(latent_array)\n",
    "\n",
    "\n",
    "def get_bayes_factor_scvi(cset_a, cset_b, sampling_n, cells_sampled, use_is, force_batch=None):\n",
    "    subset_a = np.random.choice(cset_a, cells_sampled)\n",
    "    subset_b = np.random.choice(cset_b, cells_sampled)\n",
    "    posterior_a = trainer.create_posterior(trainer.model, gene_dataset,\n",
    "                                           indices=subset_a)\n",
    "    posterior_b = trainer.create_posterior(trainer.model, gene_dataset,\n",
    "                                           indices=subset_b)\n",
    "    px_scale_a, log_ratios_a, labels_a = posterior_a.differential_expression_stats(M_sampling=sampling_n,\n",
    "                                                                                   force_batch=force_batch)\n",
    "    px_scale_b, log_ratios_b, labels_b = posterior_b.differential_expression_stats(M_sampling=sampling_n,\n",
    "                                                                                   force_batch=force_batch)\n",
    "    px_scale = np.concatenate((px_scale_a, px_scale_b), axis=1)\n",
    "    log_ratios = np.concatenate((log_ratios_a, log_ratios_b), axis=1)\n",
    "    labels_de = np.concatenate((0 * labels_a, 0 * labels_b + 1), axis=0)\n",
    "    return get_IS_bayes_factors(px_scale, log_ratios, labels_de, 0,\n",
    "                                other_cell_idx=1,\n",
    "                                importance_sampling=use_is, permutation=False)\n",
    "\n",
    "\n",
    "def eval_bayes_factor(log_fold_change, bayes_f):\n",
    "    \"\"\"\n",
    "    :param log_fold_change: groundtruth\n",
    "    :param bayes_f: non-log Bayes Factor\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bayes_f = np.log(bayes_f + 1e-8) - np.log(1 - bayes_f + 1e-8)\n",
    "    auc_1 = roc_auc_score(np.abs(log_fold_change) >= 0.6, np.abs(bayes_f))\n",
    "    auc_2 = roc_auc_score(np.abs(log_fold_change) >= 0.8, np.abs(bayes_f))\n",
    "    spear = spearmanr(bayes_f, log_fold_change)[0]\n",
    "    kend = kendalltau(bayes_f, log_fold_change)[0]\n",
    "    return auc_1, auc_2, spear, kend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling from 20000 to 9888 cells\n",
      "Downsampling from 20000 to 10112 cells\n",
      "Keeping 5000 genes\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../symsim_scVI/symsim_result/DE/\"\n",
    "label_array = pd.read_csv(os.path.join(save_path, \"DE.cell_meta.csv\"),\n",
    "                          sep=\",\", index_col=0)[\"pop\"].values\n",
    "batch_array = pd.read_csv(os.path.join(save_path, \"DE.batchid.csv\"),\n",
    "                          sep=\",\", index_col=0)[\"x\"].values\n",
    "# Renumerate the batches to be between 0 and N-batches\n",
    "batch_array -= 1\n",
    "batch_array = batch_array[:, np.newaxis]\n",
    "\n",
    "count_matrix = pd.read_csv(os.path.join(save_path, \"DE.obsv.2.csv\"),\n",
    "                           sep=\",\", index_col=0).T\n",
    "\n",
    "gene_names = np.array(count_matrix.columns, dtype=str)\n",
    "\n",
    "dataset1 = GeneExpressionDataset(*GeneExpressionDataset.get_attributes_from_matrix(\n",
    "    count_matrix.values, labels=label_array,batch_indices=batch_array),\n",
    "    gene_names=gene_names, cell_types=np.unique(label_array))\n",
    "\n",
    "dataset1.update_cells(batch_array.ravel()==0)\n",
    "\n",
    "count_matrix = pd.read_csv(os.path.join(save_path, \"DE.obsv.4.csv\"),\n",
    "                           sep=\",\", index_col=0).T\n",
    "\n",
    "dataset2 = GeneExpressionDataset(*GeneExpressionDataset.get_attributes_from_matrix(\n",
    "    count_matrix.values, labels=label_array,batch_indices=batch_array),\n",
    "    gene_names=gene_names, cell_types=np.unique(label_array))\n",
    "\n",
    "dataset2.update_cells(batch_array.ravel()==1)\n",
    "\n",
    "gene_dataset = GeneExpressionDataset.concat_datasets(dataset1, dataset2)\n",
    "labels = [int(gene_dataset.cell_types[i])-1 for i in gene_dataset.labels.ravel()]\n",
    "gene_dataset.labels = np.asarray(labels).reshape(len(labels),1)\n",
    "gene_dataset.cell_types = dataset2.cell_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "time to get scvi latent space 0.65\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(gene_dataset.nb_genes, n_batch=gene_dataset.n_batches, reconstruction_loss=\"zinb\", n_latent=10)\n",
    "trainer = UnsupervisedTrainer(vae,\n",
    "                              gene_dataset,\n",
    "                              train_size=0.75,\n",
    "                              use_cuda=True,\n",
    "                              frequency=5, kl=1)\n",
    "\n",
    "n_epochs = 1\n",
    "trainer.train(n_epochs=n_epochs, lr=0.001)\n",
    "start=time()\n",
    "full = trainer.create_posterior(trainer.model, gene_dataset, indices=np.arange(len(gene_dataset)))\n",
    "latent, batch_indices, _ = full.sequential().get_latent()\n",
    "print('time to get scvi latent space %.2f'%(time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring labels from scVI\n",
      "time to transfer labels using knn 0.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start=time()\n",
    "print(\"Transferring labels from scVI\")\n",
    "scVI_labels = transfer_nn_labels(np.asarray(latent), np.asarray(labels), np.asarray(batch_indices))\n",
    "print('time to transfer labels using knn %.2f'%(time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scANVI\n",
      "training: 100%|██████████| 1/1 [00:07<00:00,  7.56s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train scANVI\n",
    "print(\"Training scANVI\")\n",
    "scanvi = SCANVI(gene_dataset.nb_genes, gene_dataset.n_batches, gene_dataset.n_labels, n_latent=10)\n",
    "scanvi.load_state_dict(trainer.model.state_dict(), strict=False)\n",
    "trainer_scanvi = AlternateSemiSupervisedTrainer(scanvi, gene_dataset,\n",
    "                                                n_epochs_classifier=5, lr_classification=5 * 1e-3, kl=1)\n",
    "labelled = np.where(gene_dataset.batch_indices == 0)[0]\n",
    "np.random.shuffle(labelled)\n",
    "unlabelled = np.where(gene_dataset.batch_indices == 1)[0]\n",
    "np.random.shuffle(unlabelled)\n",
    "trainer_scanvi.labelled_set = trainer_scanvi.create_posterior(indices=labelled)\n",
    "trainer_scanvi.unlabelled_set = trainer_scanvi.create_posterior(indices=unlabelled)\n",
    "\n",
    "trainer_scanvi.train(n_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring labels from scVI\n",
      "time to transfer labels using scanvi 0.68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start=time()\n",
    "print(\"Transferring labels from scVI\")\n",
    "scanvi_labels = trainer_scanvi.full_dataset.sequential().compute_predictions()[1]\n",
    "print('time to transfer labels using scanvi %.2f'%(time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012 2014\n",
      "time to compute bayes factor 3.62\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "set_a = np.where(\n",
    "    np.logical_and(labels == 0, gene_dataset.batch_indices.ravel() == 0))[0]\n",
    "set_b = np.where(\n",
    "    np.logical_and(labels == 1, gene_dataset.batch_indices.ravel() == 0))[0]\n",
    "print(len(set_a),len(set_b))\n",
    "bayes_A = get_bayes_factor_scvi(set_a, set_b, 10, 1000, use_is=False)\n",
    "print('time to compute bayes factor %.2f'%(time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_new",
   "language": "python",
   "name": "pytorch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
